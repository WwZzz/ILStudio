# æ•°æ®é›† Normalizer åŒ…è£…å™¨æŒ‡å—

## ğŸ“Œ æ¦‚è¿°

æ–°çš„æ•°æ®é›†åŒ…è£…å™¨ç³»ç»Ÿé€šè¿‡**å¤–éƒ¨åŒ…è£…**çš„æ–¹å¼ä¸ºæ•°æ®é›†æ·»åŠ å½’ä¸€åŒ–åŠŸèƒ½ï¼Œè€Œä¸éœ€è¦æ¯ä¸ªæ•°æ®é›†ç±»å®ç° `set_action_normalizers` å’Œ `set_state_normalizers` æ–¹æ³•ã€‚

## âœ¨ æ ¸å¿ƒä¼˜åŠ¿

1. **æ— ä¾µå…¥æ€§**: æ•°æ®é›†ç±»ä¸éœ€è¦å®ç°ä»»ä½•ç‰¹å®šçš„å½’ä¸€åŒ–æ–¹æ³•
2. **çµæ´»æ”¯æŒ**: ä½¿ç”¨é¸­å­ç±»å‹ï¼ˆduck typingï¼‰ï¼Œæ”¯æŒä»»ä½•å®ç°æ ‡å‡†æ¥å£çš„æ•°æ®é›†
3. **ä¿æŒåŸæœ‰æ€§è´¨**: 
   - Map-style æ•°æ®é›†ï¼ˆæœ‰ `__getitem__` å’Œ `__len__`ï¼‰â†’ åŒ…è£…åä»æ˜¯ map-style
   - Iterable æ•°æ®é›†ï¼ˆæœ‰ `__iter__`ï¼‰â†’ åŒ…è£…åä»æ˜¯ iterable
4. **é€æ˜è½¬å‘**: åŒ…è£…å™¨é€æ˜åœ°è½¬å‘æ‰€æœ‰å±æ€§å’Œæ–¹æ³•è°ƒç”¨åˆ°åŸå§‹æ•°æ®é›†

## ğŸ”§ å®ç°åŸç†

### é¸­å­ç±»å‹æ£€æµ‹

åŒ…è£…å™¨ä½¿ç”¨é¸­å­ç±»å‹æ¥æ£€æµ‹æ•°æ®é›†ç±»å‹ï¼Œè€Œä¸æ˜¯æ£€æŸ¥ç»§æ‰¿å…³ç³»ï¼š

```python
# æ£€æŸ¥æ•°æ®é›†å®ç°äº†å“ªäº›æ–¹æ³•
has_getitem = hasattr(dataset, '__getitem__') and callable(getattr(dataset, '__getitem__'))
has_iter = hasattr(dataset, '__iter__') and callable(getattr(dataset, '__iter__'))
has_len = hasattr(dataset, '__len__') and callable(getattr(dataset, '__len__'))

# æ ¹æ®æ–¹æ³•åˆ¤æ–­ç±»å‹
if has_getitem and has_len:
    # Map-style æ•°æ®é›†
    return NormalizedMapDataset(...)
elif has_iter:
    # Iterable æ•°æ®é›†
    return NormalizedIterableDataset(...)
```

### ä¸¤ç§åŒ…è£…å™¨ç±»

#### 1. `NormalizedMapDataset` - Map-style æ•°æ®é›†åŒ…è£…å™¨

ç”¨äºæœ‰ `__getitem__` å’Œ `__len__` æ–¹æ³•çš„æ•°æ®é›†ï¼š

```python
class NormalizedMapDataset(Dataset):
    def __getitem__(self, idx):
        sample = self.dataset[idx]  # ä»åŸå§‹æ•°æ®é›†è·å–æ ·æœ¬
        # åº”ç”¨å½’ä¸€åŒ–
        if self.action_normalizer:
            sample['action'] = self.action_normalizer.normalize(sample['action'])
        if self.state_normalizer:
            sample['state'] = self.state_normalizer.normalize(sample['state'])
        return sample
    
    def __len__(self):
        return len(self.dataset)
```

#### 2. `NormalizedIterableDataset` - Iterable æ•°æ®é›†åŒ…è£…å™¨

ç”¨äºæœ‰ `__iter__` æ–¹æ³•çš„æ•°æ®é›†ï¼š

```python
class NormalizedIterableDataset(IterableDataset):
    def __iter__(self):
        for sample in self.dataset:  # è¿­ä»£åŸå§‹æ•°æ®é›†
            # åº”ç”¨å½’ä¸€åŒ–
            if self.action_normalizer:
                sample['action'] = self.action_normalizer.normalize(sample['action'])
            if self.state_normalizer:
                sample['state'] = self.state_normalizer.normalize(sample['state'])
            yield sample
```

## ğŸ’» ä½¿ç”¨æ–¹æ³•

### è‡ªåŠ¨åŒ…è£…ï¼ˆæ¨èï¼‰

ä½¿ç”¨ `wrap_dataset_with_normalizers` å‡½æ•°è‡ªåŠ¨æ£€æµ‹å¹¶åŒ…è£…ï¼š

```python
from data_utils.dataset_wrappers import wrap_dataset_with_normalizers

# åˆ›å»ºåŸå§‹æ•°æ®é›†
dataset = MyDataset(...)

# å‡†å¤‡ normalizers
action_normalizers = {dataset_name: action_normalizer}
state_normalizers = {dataset_name: state_normalizer}

# è‡ªåŠ¨åŒ…è£…
wrapped_dataset = wrap_dataset_with_normalizers(
    dataset=dataset,
    action_normalizers=action_normalizers,
    state_normalizers=state_normalizers,
    dataset_name=dataset_name
)

# åŒ…è£…åçš„æ•°æ®é›†å¯ä»¥ç›´æ¥ä½¿ç”¨
sample = wrapped_dataset[0]  # è¿”å›å·²å½’ä¸€åŒ–çš„æ ·æœ¬
```

### æ‰‹åŠ¨åŒ…è£…

å¦‚æœä½ çŸ¥é“æ•°æ®é›†ç±»å‹ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨å¯¹åº”çš„åŒ…è£…å™¨ï¼š

```python
from data_utils.dataset_wrappers import NormalizedMapDataset, NormalizedIterableDataset

# Map-style æ•°æ®é›†
wrapped_map = NormalizedMapDataset(
    dataset=my_map_dataset,
    action_normalizers=action_normalizers,
    state_normalizers=state_normalizers
)

# Iterable æ•°æ®é›†
wrapped_iterable = NormalizedIterableDataset(
    dataset=my_iterable_dataset,
    action_normalizers=action_normalizers,
    state_normalizers=state_normalizers
)
```

## ğŸ“ æ”¯æŒçš„æ•°æ®é›†ç±»å‹

### âœ… åŸç”Ÿæ”¯æŒ

1. **ç»§æ‰¿è‡ª `torch.utils.data.Dataset` çš„ç±»**
   - ä¾‹å¦‚ï¼š`EpisodicDataset`, `AlohaSimDataset`, `RobomimicDataset` ç­‰

2. **ç»§æ‰¿è‡ª `torch.utils.data.IterableDataset` çš„ç±»**
   - ä¾‹å¦‚ï¼š`WrappedTFDSDataset`, `DroidRLDSDataset` ç­‰

3. **ä»»ä½•å®ç°æ ‡å‡†æ¥å£çš„è‡ªå®šä¹‰ç±»**ï¼ˆæ— éœ€ç»§æ‰¿ PyTorch åŸºç±»ï¼‰
   - Map-style: å®ç° `__getitem__` å’Œ `__len__`
   - Iterable: å®ç° `__iter__`

### ç¤ºä¾‹ï¼šè‡ªå®šä¹‰æ•°æ®é›†ç±»

```python
# ä¸éœ€è¦ç»§æ‰¿ä»»ä½•åŸºç±»ï¼Œåªè¦å®ç°æ­£ç¡®çš„æ–¹æ³•å³å¯
class MyCustomMapDataset:
    def __init__(self, data):
        self.data = data
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]

# è¿™ä¸ªè‡ªå®šä¹‰ç±»ä¼šè¢«è‡ªåŠ¨è¯†åˆ«ä¸º map-style å¹¶æ­£ç¡®åŒ…è£…
wrapped = wrap_dataset_with_normalizers(
    dataset=MyCustomMapDataset(data),
    action_normalizers=normalizers,
    state_normalizers=normalizers
)
```

## ğŸ”„ ä¸ç°æœ‰ä»£ç çš„é›†æˆ

åœ¨ `data_utils/utils.py` ä¸­ï¼ŒåŸæ¥çš„ä»£ç ï¼š

```python
# âŒ æ—§æ–¹å¼ï¼šéœ€è¦æ•°æ®é›†å®ç°ç‰¹å®šæ–¹æ³•
for dataset in datasets:
    dataset.set_action_normalizers(action_normalizers)
    dataset.set_state_normalizers(state_normalizers)
```

å·²ç»è¢«æ›¿æ¢ä¸ºï¼š

```python
# âœ… æ–°æ–¹å¼ï¼šä½¿ç”¨åŒ…è£…å™¨ï¼Œæ— éœ€æ•°æ®é›†å®ç°ç‰¹å®šæ–¹æ³•
from data_utils.dataset_wrappers import wrap_dataset_with_normalizers

wrapped_datasets = []
for dataset in datasets:
    dataset_name = dataset.get_dataset_dir() if hasattr(dataset, 'get_dataset_dir') else None
    wrapped_dataset = wrap_dataset_with_normalizers(
        dataset=dataset,
        action_normalizers=action_normalizers,
        state_normalizers=state_normalizers,
        dataset_name=dataset_name
    )
    wrapped_datasets.append(wrapped_dataset)
```

## ğŸ¯ å…³é”®ç‰¹æ€§

### 1. å±æ€§å’Œæ–¹æ³•é€æ˜è½¬å‘

åŒ…è£…å™¨ä¼šå°†æ‰€æœ‰æœªçŸ¥çš„å±æ€§å’Œæ–¹æ³•è°ƒç”¨è½¬å‘ç»™åŸå§‹æ•°æ®é›†ï¼š

```python
# å¯ä»¥ç›´æ¥è°ƒç”¨åŸå§‹æ•°æ®é›†çš„æ–¹æ³•
wrapped_dataset.get_dataset_dir()  # è½¬å‘åˆ° dataset.get_dataset_dir()
wrapped_dataset.initialize()        # è½¬å‘åˆ° dataset.initialize()
wrapped_dataset.custom_method()     # è½¬å‘åˆ° dataset.custom_method()
```

### 2. è‡ªåŠ¨æ•°æ®é›†åç§°æ¨æ–­

åŒ…è£…å™¨ä¼šå°è¯•è‡ªåŠ¨æ¨æ–­æ•°æ®é›†åç§°æ¥æŸ¥æ‰¾å¯¹åº”çš„ normalizerï¼š

```python
# å°è¯•æŒ‰ä¼˜å…ˆçº§è·å–æ•°æ®é›†åç§°
if hasattr(dataset, 'dataset_dir'):
    dataset_name = dataset.dataset_dir
elif hasattr(dataset, 'dataset_path_list'):
    dataset_name = dataset.dataset_path_list[0]
elif hasattr(dataset, 'get_dataset_dir'):
    dataset_name = dataset.get_dataset_dir()
```

### 3. åªå½’ä¸€åŒ–éœ€è¦çš„å­—æ®µ

åªæœ‰å½“ `action` æˆ– `state` å­—æ®µå­˜åœ¨æ—¶æ‰ä¼šåº”ç”¨å½’ä¸€åŒ–ï¼š

```python
# åªå½’ä¸€åŒ–å­˜åœ¨çš„å­—æ®µ
if self.action_normalizer is not None and 'action' in sample:
    sample['action'] = self.action_normalizer.normalize(sample['action'])

if self.state_normalizer is not None and 'state' in sample:
    sample['state'] = self.state_normalizer.normalize(sample['state'])
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•ä»¥éªŒè¯åŒ…è£…å™¨åŠŸèƒ½ï¼š

```bash
cd /home/wz/project/IL-Studio
python -m data_utils.test_dataset_wrappers
```

æµ‹è¯•æ¶µç›–ï¼š
- âœ… Map-style æ•°æ®é›†åŒ…è£…
- âœ… Iterable æ•°æ®é›†åŒ…è£…
- âœ… è‡ªåŠ¨ç±»å‹æ£€æµ‹
- âœ… é¸­å­ç±»å‹å¯¹è‡ªå®šä¹‰ç±»çš„æ”¯æŒ
- âœ… å±æ€§è½¬å‘
- âœ… å½’ä¸€åŒ–æ­£ç¡®æ€§

## ğŸ“š ç›¸å…³æ–‡ä»¶

- **`data_utils/dataset_wrappers.py`** - åŒ…è£…å™¨å®ç°
- **`data_utils/test_dataset_wrappers.py`** - æµ‹è¯•ä»£ç 
- **`data_utils/utils.py`** - åœ¨æ•°æ®åŠ è½½æµç¨‹ä¸­ä½¿ç”¨åŒ…è£…å™¨

## ğŸ“ æœ€ä½³å®è·µ

1. **æ–°æ•°æ®é›†å¼€å‘**: åªéœ€å®ç° `__getitem__`+`__len__` æˆ– `__iter__`ï¼Œæ— éœ€å…³å¿ƒå½’ä¸€åŒ–é€»è¾‘
2. **å·²æœ‰æ•°æ®é›†**: æ— éœ€ä¿®æ”¹ï¼ŒåŒ…è£…å™¨è‡ªåŠ¨å¤„ç†
3. **è‡ªå®šä¹‰å½’ä¸€åŒ–**: å¦‚æœéœ€è¦ç‰¹æ®Šçš„å½’ä¸€åŒ–é€»è¾‘ï¼Œå¯ä»¥åœ¨æ•°æ®é›†å†…éƒ¨å¤„ç†ï¼ŒåŒ…è£…å™¨åªä¼šæ·»åŠ é¢å¤–çš„å½’ä¸€åŒ–å±‚
4. **è°ƒè¯•**: åŒ…è£…å™¨å®Œå…¨é€æ˜ï¼Œå¯ä»¥ç›´æ¥è®¿é—®åŸå§‹æ•°æ®é›†çš„æ‰€æœ‰æ–¹æ³•å’Œå±æ€§

## ğŸ”® æœªæ¥æ‰©å±•

åŒ…è£…å™¨è®¾è®¡å…è®¸è½»æ¾æ·»åŠ æ›´å¤šåŠŸèƒ½ï¼š
- æ•°æ®å¢å¼ºåŒ…è£…å™¨
- ç¼“å­˜åŒ…è£…å™¨
- é‡‡æ ·æƒé‡åŒ…è£…å™¨
- å¤šæ¨¡æ€æ•°æ®å¤„ç†åŒ…è£…å™¨

æ¯ä¸ªåŒ…è£…å™¨éƒ½å¯ä»¥ç‹¬ç«‹å·¥ä½œï¼Œä¹Ÿå¯ä»¥é“¾å¼ç»„åˆä½¿ç”¨ã€‚

